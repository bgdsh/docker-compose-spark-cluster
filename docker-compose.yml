version: '2'
services:
  ###
  # Add your pipeline here
  ###
  spark-master:
    image: bde2020/spark-master:2.4.5-hadoop2.7
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - "constraint:node==<yourmasternode>"
  spark-worker-1:
    image: bde2020/spark-worker:2.4.5-hadoop2.7
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - "constraint:node==<yourworkernode>"
  spark-worker-2:
    image: bde2020/spark-worker:2.4.5-hadoop2.7
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - "constraint:node==<yourworkernode>"   

  ###
  # mu.semte.ch stack
  ###
  integratorui:
    image: bde2020/integrator-ui:0.4.3
    volumes:
      - ./config/integrator:/app/config
    environment:
      VIRTUAL_HOST: example.big-data-europe.eu
  monitor:
    image: bde2020/pipeline-monitor-frontend:0.2.2
    links:
      - identifier:backend
    environment:
      VIRTUAL_HOST: monitor.example.big-data-europe.eu
  identifier:
    image: semtech/mu-identifier:1.0.0
  dispatcher:
    image: semtech/mu-dispatcher:1.0.1
    volumes:
      - ./config:/config
  database:
    image: tenforce/virtuoso:1.0.0-virtuoso7.2.2
    environment:
      SPARQL_UPDATE: "true"
    ports:
      - "8890:8890"
    volumes:
      - ./data/db:/data
  pipeline:
    image: bde2020/mu-pipeline-service:0.1.0
  initdaemon:
    image: bde2020/mu-init-daemon-service:0.1.0
